---
layout: about
title: about
permalink: /
subtitle: firstname.lastname@gmail.com

profile:
  align: right
  image: profile_pic2.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

  selected_papers: false # includes a list of papers marked as "selected={true}"
  social: false # includes social icons at the bottom of the page

  announcements:
    enabled: false # includes a list of news items
    scrollable: true # adds a vertical scroll bar if there are more than 3 news items
    limit: 5 # leave blank to include all the news in the `_news` folder

  latest_posts:
    enabled: false
    scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
    limit: 3 # leave blank to include all the blog posts
---

[CV](/assets/pdf/Chawin_Sitawarin_CV.pdf) &nbsp;&nbsp;&nbsp;&nbsp; [Google Scholar](https://scholar.google.com/citations?hl=en&authuser=1&user=AxUAEQ4AAAAJ)

Hello! My name is Chawin Sitawarin (ชวิน สีตวาริน).
I am a research scientist in the Security and Privacy team at Google DeepMind (Bay Area).

I am broadly interested in security and privacy aspects of machine learning with a recent focus on large language models. Most of my past works are in the domain of adversarial machine learning, particularly adversarial examples and robustness of machine learning algorithms.

I was a postdoctoral researcher in the Privacy-Preserving Machine Learning team at Meta ([Central Applied Science](https://research.facebook.com/teams/cas/)).
I obtained my PhD degree in Computer Science from UC Berkeley where I was a part of [the security group](https://security.cs.berkeley.edu/), [Berkeley Artificial Intelligence Research (BAIR)](https://bair.berkeley.edu/) and [Berkeley DeepDrive (BDD)](https://bdd-data.berkeley.edu/).
My advisor was [Prof. David Wagner](https://people.eecs.berkeley.edu/~daw/).
I have also spent some time at IBM Research, Nokia Bell Labs, Google Brain, and Google Research.

- I maintain a list of publications on security and privacy of large language models at [llm-sp](https://github.com/chawins/llm-sp).
- I used to keep track of papers on adversarial examples, but I stopped after the number of papers has become overwhelming. You can still find the list [here](https://github.com/chawins/Adversarial-Examples-Reading-List) (last update: Sep 2019).
